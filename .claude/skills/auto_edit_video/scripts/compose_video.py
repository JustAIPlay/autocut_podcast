#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
import json
import subprocess
import shutil
import argparse
from pathlib import Path
from utils import run_command, format_ffmpeg_path, check_env, get_ffmpeg_cmd, get_project_root, get_script_paths
from vertical_layout import (
    generate_vertical_layout_filter,
    generate_vertical_zoompan_filter,
    generate_subtitle_style,
    LAYOUT_WIDTH,
    LAYOUT_HEIGHT,
    IMAGE_HEIGHT
)
from desensitize_subtitles import desensitize_srt, print_report

def get_ffprobe_cmd():
    """è·å– ffprobe å‘½ä»¤è·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨æœ¬åœ°å®‰è£…ï¼‰"""
    PROJECT_ROOT = get_project_root()
    ffprobe_path = PROJECT_ROOT / "tools" / "ffmpeg" / "ffmpeg-master-latest-win64-gpl" / "bin" / "ffprobe.exe"
    return str(ffprobe_path) if ffprobe_path.exists() else "ffprobe"

def get_audio_duration(audio_path):
    """è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰"""
    cmd = [
        get_ffprobe_cmd(), '-v', 'error', '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1', str(audio_path)
    ]
    result = subprocess.run(cmd, capture_output=True, text=True)
    return float(result.stdout.strip())

def generate_zoompan_filter(effect, duration, fps=30):
    """
    æ ¹æ®åŠ¨æ•ˆé…ç½®ç”Ÿæˆ FFmpeg zoompan æ»¤é•œå­—ç¬¦ä¸²
    
    Args:
        effect: åŠ¨æ•ˆé…ç½®å­—å…¸
        duration: æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        fps: å¸§ç‡
    
    Returns:
        zoompan æ»¤é•œå­—ç¬¦ä¸²
    """
    frames = int(duration * fps)
    effect_type = effect.get('type', 'zoom_in')
    zoom_start = effect.get('zoom_start', 1.0)
    zoom_end = effect.get('zoom_end', 1.3)
    
    # è®¡ç®—ç¼©æ”¾é€Ÿåº¦ï¼ˆæ¯å¸§çš„ç¼©æ”¾å˜åŒ–é‡ï¼‰
    zoom_speed = (zoom_end - zoom_start) / frames
    
    if effect_type == 'zoom_in':
        # æ¸è¿›æ”¾å¤§
        zoom_expr = f"'min(zoom+{abs(zoom_speed)},{zoom_end})'"
        x_expr = "'iw/2-(iw/zoom/2)'"
        y_expr = "'ih/2-(ih/zoom/2)'"
    elif effect_type == 'zoom_out':
        # æ¸è¿›ç¼©å°
        zoom_expr = f"'if(lte(zoom,{zoom_end}),{zoom_start},max({zoom_end},zoom-{abs(zoom_speed)}))'"
        x_expr = "'iw/2-(iw/zoom/2)'"
        y_expr = "'ih/2-(ih/zoom/2)'"
    elif effect_type == 'pan_right':
        # å‘å³å¹³ç§» + è½»å¾®ç¼©æ”¾
        zoom_expr = f"'{zoom_start}'"
        x_expr = "'iw/2-(iw/zoom/2)+on*2'"  # on æ˜¯å¸§æ•°ï¼Œä¹˜ä»¥é€Ÿåº¦ç³»æ•°
        y_expr = "'ih/2-(ih/zoom/2)'"
    elif effect_type == 'pan_left':
        # å‘å·¦å¹³ç§» + è½»å¾®ç¼©æ”¾
        zoom_expr = f"'{zoom_start}'"
        x_expr = "'iw/2-(iw/zoom/2)-on*2'"
        y_expr = "'ih/2-(ih/zoom/2)'"
    else:
        # é»˜è®¤ï¼šè½»å¾®æ”¾å¤§
        zoom_expr = f"'min(zoom+0.0015,1.2)'"
        x_expr = "'iw/2-(iw/zoom/2)'"
        y_expr = "'ih/2-(ih/zoom/2)'"
    
    # æ„å»º zoompan æ»¤é•œ
    # s=1920x1080 æ˜¯è¾“å‡ºåˆ†è¾¨ç‡ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
    zoompan = f"zoompan=z={zoom_expr}:x={x_expr}:y={y_expr}:d={frames}:s=1920x1080:fps={fps}"
    
    return zoompan

def compose_video(script_id, vertical=False, book_name=None):
    """
    æ ¹æ®è„šæœ¬ ID åˆæˆæœ€ç»ˆè§†é¢‘
    
    Args:
        script_id: è„šæœ¬ ID
        vertical: æ˜¯å¦ç”Ÿæˆ 9:16 ç«–å±è§†é¢‘ï¼ˆé»˜è®¤ False ç”Ÿæˆ 16:9 æ¨ªå±ï¼‰
        book_name: ä¹¦åï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºä»é…ç½®æ–‡ä»¶åŒ¹é…å¹¶åŠ è½½å¯¹åº”çš„æ–‡æ¡ˆï¼Œå¦‚ï¼š"èº«ä½“é‡ç½®"
    """
    if not check_env():
        return False
    
    mode_text = "9:16 ç«–å±" if vertical else "16:9 æ¨ªå±"
    print(f"ğŸ“± è§†é¢‘æ¨¡å¼: {mode_text}")

    # ä½¿ç”¨ç»Ÿä¸€çš„è·¯å¾„ç®¡ç†
    paths = get_script_paths(script_id)
    scenes_json = paths["scenes"]
    captions_json = paths["word_timestamps"]  # ä½¿ç”¨ ForcedAligner ç”Ÿæˆçš„è¯çº§æ—¶é—´æˆ³
    audio_path = paths["audio_tts"]  # ä½¿ç”¨ TTS ç”Ÿæˆçš„äºŒåˆ›éŸ³é¢‘
    srt_path = paths["caption_final_srt"]  # æœ€ç»ˆä¼˜åŒ–å­—å¹•
    output_video = paths["final_video"]
    finals_dir = output_video.parent
    concat_file = srt_path.parent / f"{script_id}_concat.txt"
    
    # å¦‚æœ TTS éŸ³é¢‘ä¸å­˜åœ¨ï¼Œå›é€€åˆ°åŸå§‹éŸ³é¢‘
    if not audio_path.exists():
        audio_path = paths["audio"]
        print(f"âš ï¸ TTS éŸ³é¢‘ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘: {audio_path}")

    if not scenes_json.exists() or not audio_path.exists() or not captions_json.exists():
        print(f"âŒ æ‰¾ä¸åˆ°å¿…è¦æ–‡ä»¶:")
        print(f"   - scenes.json: {'âœ…' if scenes_json.exists() else 'âŒ'} {scenes_json}")
        print(f"   - word_timestamps.json: {'âœ…' if captions_json.exists() else 'âŒ'} {captions_json}")
        print(f"   - audio: {'âœ…' if audio_path.exists() else 'âŒ'} {audio_path}")
        return False

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    finals_dir.mkdir(parents=True, exist_ok=True)

    print(f"ğŸš€ æ­£åœ¨åˆæˆé¡¹ç›®: {script_id} ...")
    
    # 1. å‡†å¤‡æ•°æ®
    with open(scenes_json, 'r', encoding='utf-8') as f:
        scenes_data = json.load(f)
    
    # å…¼å®¹æ–°æ—§æ ¼å¼
    if isinstance(scenes_data, dict) and "scenes" in scenes_data:
        # æ–°æ ¼å¼ï¼šåŒ…å« metadata
        scenes = scenes_data["scenes"]
        metadata = scenes_data.get("metadata", {})
        # ä¼˜å…ˆä½¿ç”¨ scenes.json ä¸­çš„ä¹¦åï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å‚æ•°ä¼ å…¥çš„ä¹¦å
        if not book_name:
            book_name = metadata.get("book_name")
        print(f"ğŸ“– ä¹¦å: {book_name if book_name else 'æœªæŒ‡å®šï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰'}")
    else:
        # æ—§æ ¼å¼ï¼šçº¯æ•°ç»„
        scenes = scenes_data
    
    with open(captions_json, 'r', encoding='utf-8') as f:
        caption_data = json.load(f)
        segments = caption_data.get('segments', [])

    # 2. è®¡ç®—æ¯ä¸€é•œçš„æ—¶é•¿ (éŸ³ç”»å¯¹é½æ ¸å¿ƒé€»è¾‘)
    # ä½¿ç”¨åŸºäºå­—ç¬¦ä½ç½®ç´¯è®¡çš„åŒ¹é…ç®—æ³•ï¼Œæ¯”å­ä¸²åŒ¹é…æ›´ç¨³å¥
    
    # è¾…åŠ©å‡½æ•°ï¼šæ ‡å‡†åŒ–æ–‡æœ¬ï¼ˆå»é™¤æ ‡ç‚¹å’Œç©ºæ ¼ï¼‰ä»¥ä¾¿åŒ¹é…
    def normalize(text):
        return "".join(c for c in text if c.isalnum())

    # å…¨å±€æ—¶é—´åç§»ä¿®æ­£ (ç§’)ï¼Œå¦‚æœå£°éŸ³æ¯”ç”»é¢å¿«ï¼Œè®¾ä¸ºæ­£å€¼ï¼›åä¹‹è®¾ä¸ºè´Ÿå€¼
    GLOBAL_OFFSET = 0.0
    FPS = 30 # æé«˜å¸§ç‡ä»¥è·å¾—æ›´ç²¾ç»†çš„æ—¶é—´æ§åˆ¶

    # 2. æ ¸å¿ƒé€»è¾‘ï¼šå»ºç«‹å­—å¹•ç‰‡æ®µä¸åˆ†é•œå›¾ç‰‡çš„æ˜ å°„
    # ä½¿ç”¨å­—ç¬¦ä½ç½®ç´¯è®¡æ³•ï¼šæ¯ä¸ª scene è¦†ç›–ä¸€å®šçš„å­—ç¬¦èŒƒå›´
    has_written_file = False
    
    # å»ºç«‹åˆ†é•œæ–‡æœ¬åˆ°å›¾ç‰‡çš„å¿«é€Ÿç´¢å¼•ï¼Œå¹¶è®¡ç®—å­—ç¬¦èŒƒå›´
    scene_ranges = []  # [(start_char, end_char, img_path, scene_idx), ...]
    total_scene_chars = 0
    
    for idx, s in enumerate(scenes):
        img_path = Path(s['image_path'])
        if not img_path.exists():
            # å°è¯•æ—§çš„å‘½åè§„åˆ™ï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰
            alt_path_1 = img_path.parent / img_path.name.replace('_0.png', '.png')
            if alt_path_1.exists():
                img_path = alt_path_1
            else:
                # å°è¯• scene_xxx_0.png æ ¼å¼
                scene_num = s['scene']
                alt_path_2 = img_path.parent / f"scene_{scene_num:03d}_0.png"
                if alt_path_2.exists():
                    img_path = alt_path_2
        
        scene_text = normalize(s['text'])
        char_count = len(scene_text)
        scene_ranges.append({
            'start_char': total_scene_chars,
            'end_char': total_scene_chars + char_count,
            'img_path': img_path.absolute().as_posix(),
            'scene_idx': idx
        })
        total_scene_chars += char_count

    # è®¡ç®— segments çš„å­—ç¬¦ç´¯è®¡ä½ç½®
    segment_char_positions = []  # æ¯ä¸ª segment çš„èµ·å§‹å­—ç¬¦ä½ç½®
    current_char_pos = 0
    for seg in segments:
        seg_text = normalize(seg['text'])
        segment_char_positions.append({
            'start_char': current_char_pos,
            'end_char': current_char_pos + len(seg_text),
            'mid_char': current_char_pos + len(seg_text) // 2
        })
        current_char_pos += len(seg_text)
    
    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆå› ä¸º scene å’Œ segment çš„æ€»å­—ç¬¦æ•°å¯èƒ½ä¸åŒï¼‰
    total_segment_chars = current_char_pos
    scale_ratio = total_scene_chars / total_segment_chars if total_segment_chars > 0 else 1.0
    
    print(f"ğŸ“Š åŒ¹é…ç»Ÿè®¡: {len(scenes)} ä¸ªåœºæ™¯, {len(segments)} ä¸ªç‰‡æ®µ")
    print(f"   åœºæ™¯æ€»å­—ç¬¦: {total_scene_chars}, ç‰‡æ®µæ€»å­—ç¬¦: {total_segment_chars}, ç¼©æ”¾æ¯”ä¾‹: {scale_ratio:.3f}")

    # é¢„å…ˆè·å–ä¸€ä¸ªå…œåº•è·¯å¾„
    default_img = scene_ranges[0]['img_path'] if scene_ranges else ""
    
    # æ ¹æ®å­—ç¬¦ä½ç½®æ‰¾åˆ°å¯¹åº”çš„ scene
    def find_scene_for_segment(seg_idx):
        if seg_idx >= len(segment_char_positions):
            return default_img
        
        # ä½¿ç”¨ segment çš„ä¸­ç‚¹ä½ç½®æ¥å†³å®šå±äºå“ªä¸ª scene
        seg_mid_char = segment_char_positions[seg_idx]['mid_char']
        # ç¼©æ”¾åˆ° scene çš„å­—ç¬¦èŒƒå›´
        scaled_pos = seg_mid_char * scale_ratio
        
        # æ‰¾åˆ°å¯¹åº”çš„ scene
        for sr in scene_ranges:
            if sr['start_char'] <= scaled_pos < sr['end_char']:
                return sr['img_path']
        
        # å¦‚æœè¶…å‡ºèŒƒå›´ï¼Œè¿”å›æœ€åä¸€ä¸ª scene
        return scene_ranges[-1]['img_path'] if scene_ranges else default_img
    
    # éå†åŸå§‹å­—å¹•ç‰‡æ®µï¼Œä¸ºæ¯ä¸ªç‰‡æ®µåˆ†é…å¯¹åº”çš„åˆ†é•œå›¾
    current_video_time = 0.0 # è®°å½•å·²ç”Ÿæˆçš„è§†é¢‘ç²¾ç¡®æ—¶é•¿ï¼ˆåŸºäºå¸§æ•°ï¼‰
    
    with open(concat_file, 'w', encoding='utf-8') as f:
        # å†™å…¥æ–‡ä»¶å¤´æ³¨é‡Šï¼Œæ–¹ä¾¿è°ƒè¯•
        f.write(f"# FPS: {FPS}\n")

        for i, seg in enumerate(segments):
            # ç›®æ ‡æ—¶é—´ç‚¹ï¼ˆåŠ ä¸Šåç§»ï¼‰
            target_start = seg['start'] + GLOBAL_OFFSET
            target_end = seg['end'] + GLOBAL_OFFSET
            
            # ä½¿ç”¨æ–°ç®—æ³•æ‰¾åˆ°æœ€åŒ¹é…çš„åˆ†é•œå›¾
            img_path = find_scene_for_segment(i)

            if not img_path:
                print(f"âš ï¸ è­¦å‘Š: æ— æ³•æ‰¾åˆ°å›¾ç‰‡ï¼Œè·³è¿‡ç‰‡æ®µ: {seg['text']}")
                continue

            # --- å¸§å¯¹é½æ ¸å¿ƒç®—æ³• ---
            
            # 1. å¤„ç†ç©ºéš™ (Gap)
            # åªæœ‰å½“ç›®æ ‡å¼€å§‹æ—¶é—´æ˜æ˜¾æ™šäºå½“å‰è§†é¢‘æ—¶é—´ï¼ˆè¶…è¿‡1å¸§ï¼‰æ—¶æ‰è¡¥é»‘/è¡¥å›¾
            if target_start > current_video_time + (1.0/FPS):
                gap_duration = target_start - current_video_time
                # é‡åŒ–ç©ºéš™æ—¶é•¿
                gap_frames = round(gap_duration * FPS)
                gap_final = gap_frames / FPS
                
                if gap_final > 0:
                    if has_written_file:
                        f.write(f"duration {gap_final:.3f}\n")
                    else:
                        # å¼€å¤´ç©ºéš™ï¼Œç”¨ç¬¬ä¸€å¼ å›¾å¡«è¡¥
                        f.write(f"file '{img_path}'\n")
                        f.write(f"duration {gap_final:.3f}\n")
                    
                    current_video_time += gap_final

            # 2. è®¡ç®—å½“å‰å›¾ç‰‡åº”è¯¥æŒç»­åˆ°ä»€ä¹ˆæ—¶é—´ç‚¹
            # é»˜è®¤æ˜¯å½“å‰å¥å­çš„ç»“æŸæ—¶é—´
            segment_target_end = target_end
            
            # æ£€æŸ¥ä¸‹ä¸€å¥æ˜¯å¦é‡å 
            if i < len(segments) - 1:
                next_start = segments[i+1]['start'] + GLOBAL_OFFSET
                if next_start < segment_target_end:
                    segment_target_end = next_start
            
            # 3. è®¡ç®—æœ¬ç‰‡æ®µéœ€è¦çš„æ—¶é•¿ (ç›®æ ‡ç»“æŸæ—¶é—´ - å½“å‰å·²ç”Ÿæˆæ—¶é—´)
            # è¿™æ ·æ¯æ¬¡è®¡ç®—éƒ½æ˜¯åŸºäºç»å¯¹æ—¶é—´è½´ï¼Œè¯¯å·®ä¸ä¼šç´¯ç§¯ï¼
            needed_duration = segment_target_end - current_video_time
            
            # é‡åŒ–æ—¶é•¿
            frames = round(needed_duration * FPS)
            final_duration = frames / FPS
            
            # å®¹é”™ï¼šé˜²æ­¢ duration < 0
            if final_duration < 0:
                 final_duration = 0.0

            # 4. å†™å…¥
            if final_duration > 0:
                f.write(f"file '{img_path}'\n")
                f.write(f"duration {final_duration:.3f}\n")
                has_written_file = True
                current_video_time += final_duration

        # è¡¥é½æœ€åä¸€ç‚¹æ—¶é—´
        total_audio_duration = get_audio_duration(audio_path)
        if total_audio_duration > current_video_time:
            remaining = total_audio_duration - current_video_time
            frames = round(remaining * FPS)
            final_remaining = frames / FPS
            if final_remaining > 0:
                f.write(f"duration {final_remaining:.3f}\n")
            
        # FFmpeg concat æƒ¯ä¾‹ï¼šæœ€åé‡å¤ä¸€æ¬¡æœ€åä¸€å¼ å›¾
        if has_written_file:
            f.write(f"file '{img_path}'\n")
            
    # 3. ä¸ºæ¯å¼ å›¾ç‰‡ç”Ÿæˆå¸¦åŠ¨æ•ˆçš„è§†é¢‘ç‰‡æ®µ
    print("\nğŸ¬ æ­£åœ¨ä¸ºæ¯å¼ å›¾ç‰‡ç”ŸæˆåŠ¨æ•ˆè§†é¢‘ç‰‡æ®µ...")
    temp_segments_dir = finals_dir / f"{script_id}_temp_segments"
    temp_segments_dir.mkdir(parents=True, exist_ok=True)
    
    # è§£æ concat.txtï¼Œå»ºç«‹å›¾ç‰‡åˆ°æ—¶é•¿çš„æ˜ å°„
    scene_durations = {}
    current_img = None
    with open(concat_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line.startswith('file '):
                current_img = line.replace("file '", "").replace("'", "")
            elif line.startswith('duration ') and current_img:
                duration = float(line.replace('duration ', ''))
                # ç´¯åŠ ç›¸åŒå›¾ç‰‡çš„æ—¶é•¿
                if current_img in scene_durations:
                    scene_durations[current_img] += duration
                else:
                    scene_durations[current_img] = duration
    
    # ä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆå¸¦åŠ¨æ•ˆçš„è§†é¢‘ç‰‡æ®µ
    segment_files = []
    for i, scene in enumerate(scenes):
        scene_num = scene['scene']
        img_path = Path(scene['image_path'])
        
        # æŸ¥æ‰¾å›¾ç‰‡å¯¹åº”çš„æ—¶é•¿
        img_path_str = str(img_path.absolute().as_posix())
        duration = scene_durations.get(img_path_str, 5.0)  # é»˜è®¤5ç§’
        
        if duration <= 0:
            continue
        
        # è·å–åŠ¨æ•ˆé…ç½®
        effect = scene.get('effect', {'type': 'zoom_in', 'zoom_start': 1.0, 'zoom_end': 1.2})
        
        # ç”Ÿæˆ zoompan æ»¤é•œï¼ˆæ ¹æ®è§†é¢‘æ¨¡å¼é€‰æ‹©ï¼‰
        if vertical:
            zoompan_filter = generate_vertical_zoompan_filter(effect, duration, FPS)
        else:
            zoompan_filter = generate_zoompan_filter(effect, duration, FPS)
        
        # è¾“å‡ºç‰‡æ®µè·¯å¾„
        segment_path = temp_segments_dir / f"scene_{scene_num:03d}.mp4"
        segment_files.append(segment_path)
        
        # å¦‚æœç‰‡æ®µå·²å­˜åœ¨ï¼Œè·³è¿‡
        if segment_path.exists():
            print(f"â© åœºæ™¯ {scene_num} çš„è§†é¢‘ç‰‡æ®µå·²å­˜åœ¨ï¼Œè·³è¿‡")
            continue
        
        print(f"ğŸ¨ ç”Ÿæˆåœºæ™¯ {scene_num} çš„åŠ¨æ•ˆè§†é¢‘ ({effect['type']}, {duration:.2f}ç§’)...")
        
        # æ„å»ºæ»¤é•œé“¾
        if vertical:
            # ç«–å±æ¨¡å¼ï¼šzoompan + å¸ƒå±€æ»¤é•œ
            layout_filters = generate_vertical_layout_filter(book_name=book_name)
            full_filter = zoompan_filter + "," + ",".join(layout_filters)
        else:
            # æ¨ªå±æ¨¡å¼ï¼šä»… zoompan
            full_filter = zoompan_filter
        
        # ç”Ÿæˆå¸¦åŠ¨æ•ˆçš„è§†é¢‘ç‰‡æ®µ
        cmd_segment = [
            get_ffmpeg_cmd(),
            '-loop', '1',
            '-i', str(img_path.absolute()),
            '-vf', full_filter,
            '-t', str(duration),
            '-c:v', 'libx264',
            '-pix_fmt', 'yuv420p',
            '-r', str(FPS),
            '-y', str(segment_path)
        ]
        
        if run_command(cmd_segment, f"åœºæ™¯ {scene_num} åŠ¨æ•ˆç”Ÿæˆå¤±è´¥") is None:
            print(f"âš ï¸ è­¦å‘Š: åœºæ™¯ {scene_num} åŠ¨æ•ˆç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡")
            continue
    
    # ç”Ÿæˆæ–°çš„ concat æ–‡ä»¶ï¼ˆæŒ‡å‘è§†é¢‘ç‰‡æ®µï¼‰
    concat_file_segments = srt_path.parent / f"{script_id}_concat_segments.txt"
    with open(concat_file_segments, 'w', encoding='utf-8') as f:
        for segment_path in segment_files:
            if segment_path.exists():
                f.write(f"file '{segment_path.absolute().as_posix()}'\n")
    
    # 4. åˆå¹¶æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
    print("\nğŸ¬ æ­£åœ¨åˆå¹¶æ‰€æœ‰åŠ¨æ•ˆè§†é¢‘ç‰‡æ®µ...")
    temp_video = finals_dir / f"{script_id}_temp_silent.mp4"
    cmd_base = [
        get_ffmpeg_cmd(), '-f', 'concat', '-safe', '0', '-i', str(concat_file_segments),
        '-c:v', 'copy',  # ç›´æ¥å¤åˆ¶ï¼Œä¸é‡æ–°ç¼–ç 
        '-y', str(temp_video)
    ]
    if run_command(cmd_base, "è§†é¢‘ç‰‡æ®µåˆå¹¶å¤±è´¥") is None:
        return False

    # 3. å­—å¹•è„±æ•å¤„ç†
    print("\nğŸ”’ æ­£åœ¨å¯¹å­—å¹•è¿›è¡Œè„±æ•å¤„ç†...")
    desensitized_srt_path = srt_path.parent / f"{script_id}_final_desensitized.srt"
    
    try:
        report = desensitize_srt(srt_path, desensitized_srt_path)
        print_report(report)
        # ä½¿ç”¨è„±æ•åçš„å­—å¹•æ–‡ä»¶
        srt_to_use = desensitized_srt_path
    except Exception as e:
        print(f"âš ï¸ è­¦å‘Š: å­—å¹•è„±æ•å¤±è´¥ ({e})ï¼Œå°†ä½¿ç”¨åŸå§‹å­—å¹•")
        srt_to_use = srt_path
    
    # 4. åˆå¹¶éŸ³é¢‘å’Œå­—å¹•
    srt_path_fixed = format_ffmpeg_path(str(srt_to_use))
    
    # æ„å»ºå­—å¹•æ»¤é•œï¼ˆæ ¹æ®è§†é¢‘æ¨¡å¼é€‰æ‹©æ ·å¼ï¼‰
    if vertical:
        subtitle_style = generate_subtitle_style()
        subtitle_filter = f"subtitles='{srt_path_fixed}':force_style='{subtitle_style}'"
    else:
        subtitle_filter = f"subtitles='{srt_path_fixed}'"

    # çƒ§å½•å­—å¹•å¹¶åˆå¹¶éŸ³é¢‘
    cmd_final = [
        get_ffmpeg_cmd(), '-i', str(temp_video), '-i', str(audio_path.absolute()),
        '-vf', subtitle_filter,
        '-c:v', 'libx264',  # éœ€è¦é‡æ–°ç¼–ç ä»¥çƒ§å½•å­—å¹•
        '-c:a', 'aac', '-shortest', '-y', str(output_video.absolute())
    ]
    
    print("ğŸ¬ æ­£åœ¨çƒ§å½•å­—å¹•å¹¶åˆå¹¶éŸ³é¢‘...")
    if run_command(cmd_final, "æœ€ç»ˆè§†é¢‘åˆæˆå¤±è´¥") is not None:
        print(f"âœ… è§†é¢‘åˆæˆæˆåŠŸ: {output_video}")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if concat_file.exists(): concat_file.unlink()
    if concat_file_segments.exists(): concat_file_segments.unlink()
    if temp_video.exists(): temp_video.unlink()
    
    # æ¸…ç†è§†é¢‘ç‰‡æ®µç›®å½•ï¼ˆå¯é€‰ï¼Œå¦‚æœæƒ³ä¿ç•™ç‰‡æ®µç”¨äºè°ƒè¯•ï¼Œå¯ä»¥æ³¨é‡Šæ‰ï¼‰
    if temp_segments_dir.exists():
        shutil.rmtree(temp_segments_dir)
        print(f"ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶è§†é¢‘ç‰‡æ®µ")
    
    return True

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="åˆæˆè§†é¢‘")
    parser.add_argument("script_id", help="è„šæœ¬ ID")
    parser.add_argument("--vertical", "-v", action="store_true", 
                       help="ç”Ÿæˆ 9:16 ç«–å±è§†é¢‘ï¼ˆé»˜è®¤ç”Ÿæˆ 16:9 æ¨ªå±ï¼‰")
    parser.add_argument("--book", "-b", type=str, default=None,
                       help="ä¹¦åï¼ˆç”¨äºä»é…ç½®æ–‡ä»¶åŠ è½½æ–‡æ¡ˆï¼Œå¦‚: 'èº«ä½“é‡ç½®'ï¼‰")
    
    args = parser.parse_args()
    compose_video(args.script_id, vertical=args.vertical, book_name=args.book)