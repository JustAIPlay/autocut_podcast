#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Whisper è½¬å½•è„šæœ¬ - è¯è¯­çº§åˆ«æ—¶é—´çº¿ç‰ˆæœ¬
ç”Ÿæˆæ¯ä¸ªè¯éƒ½æœ‰ç‹¬ç«‹æ—¶é—´è½´çš„"å­—å¹•æ—¶é—´çº¿è¯å…¸"
"""
import os
import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
import json
from pathlib import Path
from typing import Any, List

# è®¾ç½® Hugging Face é•œåƒ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# é¢„åˆå§‹åŒ–
WhisperModel = None
whisper = None

try:
    from faster_whisper import WhisperModel
    HAS_FASTER = True
except ImportError:
    try:
        import whisper
        HAS_FASTER = False
    except ImportError:
        print("è¯·å…ˆå®‰è£… whisper: pip install openai-whisper æˆ– pip install faster-whisper")
        sys.exit(1)

def format_timestamp(seconds: float):
    """å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼"""
    td_hours = int(seconds // 3600)
    td_mins = int((seconds % 3600) // 60)
    td_secs = int(seconds % 60)
    td_millis = int((seconds - int(seconds)) * 1000)
    return f"{td_hours:02}:{td_mins:02}:{td_secs:02},{td_millis:03}"

def transcribe_word_level(script_id):
    """è¯è¯­çº§åˆ«è½¬å½•ï¼šæ¯ä¸ªè¯éƒ½æœ‰ç‹¬ç«‹çš„æ—¶é—´è½´"""
    global WhisperModel, whisper
    
    from utils import get_script_paths
    paths = get_script_paths(script_id)
    audio_path = paths["audio"]
    copy_dir = paths["copy_whisper"].parent
    caption_dir = paths["caption_whisper_srt"].parent
    
    if not audio_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        return False

    caption_dir.mkdir(parents=True, exist_ok=True)
    copy_dir.mkdir(parents=True, exist_ok=True)

    print(f"ğŸš€ æ­£åœ¨è½¬å½•é¡¹ç›®: {script_id}")
    print(f"ğŸ“Œ æ¨¡å¼: è¯è¯­çº§åˆ«æ—¶é—´çº¿ï¼ˆå­—å¹•æ—¶é—´çº¿è¯å…¸ï¼‰")
    
    full_text = ""
    segments: List[Any] = []

    if HAS_FASTER and WhisperModel is not None:
        print(f"ğŸš€ ä½¿ç”¨ faster-whisper (GPU åŠ é€Ÿæ¨¡å¼) è½¬å½•...")
        try:
            model = WhisperModel("medium", device="cuda", compute_type="float16")
        except Exception as e:
            print(f"âš ï¸ GPU åŠ é€Ÿå¯åŠ¨å¤±è´¥ï¼Œåˆ‡æ¢å› CPU æ¨¡å¼ã€‚é”™è¯¯: {e}")
            model = WhisperModel("medium", device="cpu", compute_type="int8")
        
        result_iter, info = model.transcribe(
            str(audio_path), 
            beam_size=5, 
            language="zh", 
            initial_prompt="è¿™æ˜¯ä¸€æ®µå…³äºä¹”ä¸¹Â·è²åˆ©æ™®æ–¯åŒ»ç”Ÿåœ¨ä¸­å›½æ¨å¹¿è…¹è…”é•œæ‰‹æœ¯çš„åŒ»å­¦çºªå½•ç‰‡ã€‚å…³é”®è¯ï¼šå¡è¿›å…¬æ–‡åŒ…ã€å¹æ°”ã€è…¹è…”é•œã€æ‰‹æœ¯åˆ€ã€åå’ŒåŒ»é™¢ã€‚"
        )
        
        segments = []
        for s in result_iter:
            print(f"  [{format_timestamp(s.start)}] {s.text}")
            segments.append(s)
            
        full_text = "".join([s.text for s in segments])
    elif whisper is not None:
        print("ğŸš€ ä½¿ç”¨ standard whisper è½¬å½•...")
        model = whisper.load_model("medium")
        result: Any = model.transcribe(
            str(audio_path), 
            language="zh", 
            initial_prompt="è¿™æ˜¯ä¸€æ®µå…³äºä¹”ä¸¹Â·è²åˆ©æ™®æ–¯åŒ»ç”Ÿåœ¨ä¸­å›½æ¨å¹¿è…¹è…”é•œæ‰‹æœ¯çš„åŒ»å­¦çºªå½•ç‰‡ã€‚å…³é”®è¯ï¼šå¡è¿›å…¬æ–‡åŒ…ã€å¹æ°”ã€è…¹è…”é•œã€æ‰‹æœ¯åˆ€ã€åå’ŒåŒ»é™¢ã€‚"
        )
        full_text = str(result.get("text", ""))
        segments = list(result.get("segments", []))
        for s in segments:
            print(f"  [{format_timestamp(float(s['start']))}] {s['text']}")

    # ä¿å­˜çº¯æ–‡æœ¬
    txt_path = paths["copy_whisper"]
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(full_text)
    
    # æå–åŸå§‹ segments
    raw_segments = []
    for segment in segments:
        if HAS_FASTER:
            raw_segments.append({
                "start": segment.start,
                "end": segment.end,
                "text": segment.text.strip()
            })
        else:
            raw_segments.append({
                "start": segment['start'],
                "end": segment['end'],
                "text": segment['text'].strip()
            })

    # ========== è¯è¯­çº§åˆ«åˆ†è¯ ==========
    print("\nğŸ“ æ­£åœ¨è¿›è¡Œè¯è¯­çº§åˆ«åˆ†è¯...")
    
    try:
        import jieba
        import logging
        jieba.setLogLevel(logging.INFO)
        HAS_JIEBA = True
    except ImportError:
        print("âš ï¸ è­¦å‘Šï¼šjieba æœªå®‰è£…ï¼Œå°†æŒ‰å­—ç¬¦åˆ‡åˆ†")
        print("   å»ºè®®å®‰è£…: pip install jieba")
        HAS_JIEBA = False
    
    word_segments = []
    idx = 1
    
    for seg in raw_segments:
        text = seg['text'].strip()
        if not text:
            continue
        
        start = float(seg['start'])
        end = float(seg['end'])
        duration = end - start
        total_chars = len(text)
        
        if HAS_JIEBA:
            # ä½¿ç”¨ jieba åˆ†è¯
            words = list(jieba.cut(text))
        else:
            # å›é€€åˆ°å­—ç¬¦åˆ‡åˆ†
            words = list(text)
        
        current_start = start
        for word in words:
            word = word.strip()
            if not word:
                continue
            
            # æ ¹æ®è¯è¯­å­—ç¬¦æ•°åˆ†é…æ—¶é•¿
            word_len = len(word)
            word_duration = (word_len / total_chars) * duration if total_chars > 0 else 0
            word_end = current_start + word_duration
            
            word_segments.append({
                "id": idx,
                "start": round(current_start, 3),
                "end": round(word_end, 3),
                "text": word
            })
            idx += 1
            current_start = word_end
    
    print(f"âœ… è¯è¯­çº§åˆ«åˆ†è¯å®Œæˆï¼Œå…± {len(word_segments)} ä¸ªè¯")
    
    # ä¿å­˜ JSON
    json_path = paths["caption_whisper_json"]
    output_data = {
        "script_id": script_id,
        "full_text": full_text,
        "segments": word_segments,
        "segment_mode": "word_level",
        "total_words": len(word_segments)
    }
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜ SRT
    srt_path = paths["caption_whisper_srt"]
    with open(srt_path, "w", encoding="utf-8") as f:
        for seg in word_segments:
            start_str = format_timestamp(seg['start'])
            end_str = format_timestamp(seg['end'])
            f.write(f"{seg['id']}\n{start_str} --> {end_str}\n{seg['text']}\n\n")
    
    print(f"âœ… è½¬å½•å®Œæˆï¼")
    print(f"   æ¨¡å¼: è¯è¯­çº§åˆ«æ—¶é—´çº¿")
    print(f"   è¯æ•°: {len(word_segments)}")
    print(f"   SRT: {srt_path}")
    print(f"   JSON: {json_path}")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªè¯çš„æ—¶é—´çº¿
    print(f"\nğŸ“Š å‰10ä¸ªè¯çš„æ—¶é—´çº¿ç¤ºä¾‹:")
    for seg in word_segments[:10]:
        print(f"   [{seg['start']:.3f}-{seg['end']:.3f}] \"{seg['text']}\"")
    
    return True

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python transcribe_whisper_word_level.py <script_id>")
        print("è¯´æ˜: ç”Ÿæˆè¯è¯­çº§åˆ«çš„æ—¶é—´çº¿ï¼ˆå­—å¹•æ—¶é—´çº¿è¯å…¸ï¼‰")
        sys.exit(1)
    
    transcribe_word_level(sys.argv[1])
