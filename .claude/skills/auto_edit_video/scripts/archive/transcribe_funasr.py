import re
import sys
import json
from pathlib import Path
from funasr import AutoModel

def format_time(seconds):
    """å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼ HH:MM:SS,mmm"""
    ms = int((seconds % 1) * 1000)
    s = int(seconds)
    m, s = divmod(s, 60)
    h, m = divmod(m, 60)
    return f"{h:02}:{m:02}:{s:02},{ms:03}"

def clean_text(text):
    """æ¸…ç† SenseVoice æˆ–å…¶ä»–æ¨¡å‹äº§ç”Ÿçš„ç‰¹æ®Šæ ‡ç­¾"""
    if not text:
        return ""
    # å»é™¤ <|...|> æ ¼å¼çš„æ ‡ç­¾
    text = re.sub(r'<\|.*?\|>', '', text)
    return text.strip()

def split_subtitle_text(text, max_len=9):
    """
    æ›´æ™ºèƒ½çš„å­—å¹•åˆ‡åˆ†ï¼š
    1. ä¿æŒå­—æ•°é™åˆ¶ (é»˜è®¤9å­—)
    2. ç»ä¸ä»è¯è¯­ä¸­é—´åˆ‡æ–­ (ä½¿ç”¨åˆ†è¯)
    3. â€œçš„â€ç­‰è™šè¯åŠæ ‡ç‚¹ä¸æ”¾è¡Œé¦–ï¼Œå¿…é¡»åˆå¹¶åˆ°ä¸Šä¸€è¡Œ
    4. å°½é‡ä¿æŒæ¯è¡Œé•¿åº¦å¹³è¡¡
    """
    if not text or len(text) <= max_len:
        return [text] if text else []
    
    # å°è¯•ä½¿ç”¨ jieba åˆ†è¯
    try:
        import jieba
        import logging
        jieba.setLogLevel(logging.INFO)
        words = list(jieba.cut(text))
    except ImportError:
        import re
        words = re.findall(r'[\u4e00-\u9fff]|[a-zA-Z0-9]+|[^\u4e00-\u9fffa-zA-Z0-9]', text)

    forbidden_at_start = ["çš„", "äº†", "ç€", "å„¿", "æ—¶", "ï¼‰", "ã€‘", "â€", "â€™", "ã€‹", "ï¼›", "ï¼š", "ï¼Œ", "ã€‚", "ï¼", "ï¼Ÿ", "ã€"]
    
    lines = []
    current_line = ""
    
    for word in words:
        if not current_line:
            current_line = word
            continue
            
        if len(current_line) + len(word) > max_len:
            if word in forbidden_at_start:
                current_line += word
            else:
                lines.append(current_line)
                current_line = word
        else:
            current_line += word
            
    if current_line:
        lines.append(current_line)

    if len(lines) == 2:
        total_len = len("".join(lines))
        if total_len <= max_len * 1.8:
            best_split_idx = -1
            min_diff = total_len
            curr_len = 0
            for i in range(len(words) - 1):
                curr_len += len(words[i])
                if curr_len <= max_len and (total_len - curr_len) <= max_len and words[i+1] not in forbidden_at_start:
                    diff = abs(curr_len - (total_len - curr_len))
                    if diff < min_diff:
                        min_diff = diff
                        best_split_idx = i
            if best_split_idx != -1:
                lines = ["".join(words[:best_split_idx+1]), "".join(words[best_split_idx+1:])]
                
    final_lines = []
    for line in lines:
        if all(c in forbidden_at_start for c in line) and final_lines:
            final_lines[-1] += line
        else:
            final_lines.append(line)
            
    return final_lines

def transcribe(script_id):
    # è·¯å¾„é€»è¾‘
    base_dir = Path(__file__).parent.parent.parent.parent.parent
    audio_path = base_dir / "raw_materials" / "audios" / f"{script_id}.mp3"
    copy_dir = base_dir / "raw_materials" / "copys"
    caption_dir = base_dir / "raw_materials" / "captions"

    if not audio_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        return False

    print(f"ğŸš€ æ­£åœ¨è¿˜åŸ Paraformer é»„é‡‘é…ç½®è½¬å½•: {script_id}")

    # åŠ è½½æ¨¡å‹ (å®Œå…¨åŒæ­¥ temp é¡¹ç›®é…ç½®)
    model = AutoModel(
        model="paraformer-zh",
        model_revision="v2.0.4",
        vad_model="fsmn-vad",
        vad_model_revision="v2.0.4",
        punc_model="ct-punc-c",
        punc_model_revision="v2.0.4",
        device="cuda:0",
        disable_update=True
    )

    # å¼€å§‹æ¨ç†
    res = model.generate(
        input=str(audio_path),
        batch_size_s=300,
        hotword='è…¹è…”é•œ ä¹”ä¸¹Â·è²åˆ©æ™®æ–¯ æ­¢è¡€é’³ ä»æµåŒ»é™¢ å¦‡ç§‘ æ‰‹æœ¯ è¾©å‹ æ‰‹è‰º äº§å¦‡',
        sentence_timestamp=True 
    )

    if not res or len(res) == 0:
        print("âŒ è½¬å½•å¤±è´¥")
        return False

    result = res[0]
    full_text = clean_text(result.get('text', ''))

    # 1. ä¿å­˜çº¯æ–‡æ¡ˆ
    copy_dir.mkdir(parents=True, exist_ok=True)
    txt_path = copy_dir / f"{script_id}.txt"
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(full_text)
    print(f"âœ… æ–‡æ¡ˆå·²ä¿å­˜: {txt_path}")

    # 2. æ„é€ ç»“æ„åŒ–çš„ segments æ•°æ®
    caption_dir.mkdir(parents=True, exist_ok=True)
    srt_path = caption_dir / f"{script_id}.srt"
    json_path = caption_dir / f"{script_id}.json"
    
    raw_segments = []
    sentences = result.get('sentences')
    
    if sentences:
        print(f"DEBUG: æ‰¾åˆ° {len(sentences)} æ¡å¥å­çº§æ—¶é—´è½´æ•°æ®")
        for i, s in enumerate(sentences):
            raw_segments.append({
                "start": float(s.get('start', 0)) / 1000.0,
                "end": float(s.get('end', 0)) / 1000.0,
                "text": clean_text(s.get('text', ''))
            })
    elif 'timestamp' in result and len(result['timestamp']) > 0:
        print(f"DEBUG: å¯åŠ¨å­—ç¬¦çº§æ—¶é—´æˆ³èšåˆé€»è¾‘ (ç²¾å‡†æ¨¡å¼)")
        raw_ts = result['timestamp']  # [[start, end], [start, end], ...]
        raw_text = result.get('text', '')
        
        # ç§»é™¤ç©ºæ ¼ä½†ä¿ç•™æ ‡ç‚¹ç”¨äºåˆ‡åˆ†
        chars = [c for c in raw_text if not c.isspace()]
        
        current_seg_text = ""
        current_start = -1.0
        
        # æ ‡ç‚¹ç¬¦å·å®šä¹‰
        punctuations = "ï¼Œã€‚ï¼Ÿï¼ï¼›,.;?!"
        
        for i, (ts, char) in enumerate(zip(raw_ts, chars)):
            if current_start < 0:
                current_start = float(ts[0]) / 1000.0
            
            current_seg_text += char
            
            # é‡åˆ°æ ‡ç‚¹æˆ–æœ€åä¸€ä¸ªå­—ï¼Œç»“æŸå½“å‰æ®µè½
            if char in punctuations or i == len(chars) - 1:
                end_time = float(ts[1]) / 1000.0
                if len(current_seg_text.strip()) > 1: # é¿å…åªæœ‰æ ‡ç‚¹çš„è¡Œ
                    raw_segments.append({
                        "start": round(current_start, 3),
                        "end": round(end_time, 3),
                        "text": current_seg_text.strip()
                    })
                current_start = -1.0
                current_seg_text = ""
    else:
        print("DEBUG: è­¦å‘Šï¼æœªæ‰¾åˆ°ä»»ä½•æ—¶é—´æˆ³æ•°æ®ï¼Œå¯åŠ¨å­—æ•°ä¼°ç®—å…œåº•")

    # --- å¢åŠ ï¼šåˆ‡åˆ†è¿‡é•¿å­—å¹•é€»è¾‘ (æ¯æ®µä¸è¶…è¿‡ 9 ä¸ªå­—) ---
    MAX_CHARS = 9
    segments = []
    idx = 1
    for seg in raw_segments:
        text = seg['text']
        parts = split_subtitle_text(text, MAX_CHARS)
        
        if len(parts) == 1:
            seg['id'] = idx
            segments.append(seg)
            idx += 1
        else:
            start = seg['start']
            end = seg['end']
            duration = end - start
            total_chars = len(text)
            
            current_start = start
            for part in parts:
                part_len = len(part)
                part_duration = (part_len / total_chars) * duration
                part_end = current_start + part_duration
                
                segments.append({
                    "id": idx,
                    "start": round(current_start, 3),
                    "end": round(part_end, 3),
                    "text": part
                })
                idx += 1
                current_start = part_end
    # -----------------------------------------------

    # --- å¢åŠ ï¼šæœ€åæ¸…ç†ï¼Œåˆå¹¶çº¯æ ‡ç‚¹æ®µè½æˆ–ç¦å¿Œå¼€å¤´çš„æ®µè½ ---
    final_segments = []
    forbidden_at_start = ["çš„", "äº†", "ç€", "å„¿", "æ—¶", "ï¼‰", "ã€‘", "â€", "â€™", "ã€‹", "ï¼›", "ï¼š", "ï¼Œ", "ã€‚", "ï¼", "ï¼Ÿ", "ã€"]
    for seg in segments:
        # å¦‚æœå½“å‰æ®µè½å…¨æ˜¯æ ‡ç‚¹ï¼Œæˆ–è€…å½“å‰æ®µè½ä»¥ç¦å¿Œè¯å¼€å¤´ä¸”æœ‰å‰åºæ®µè½ï¼Œåˆ™åˆå¹¶
        if final_segments and (all(c in forbidden_at_start for c in seg['text']) or seg['text'][0] in forbidden_at_start):
            final_segments[-1]['end'] = seg['end']
            final_segments[-1]['text'] += seg['text']
        else:
            final_segments.append(seg)
    
    # é‡æ–°ç¼–å·å¹¶ç¡®ä¿æ—¶é—´æˆ³ç²¾åº¦
    for i, seg in enumerate(final_segments, 1):
        seg['id'] = i
        seg['start'] = round(seg['start'], 3)
        seg['end'] = round(seg['end'], 3)
    segments = final_segments
    # ------------------------------------

    # 3. ä¿å­˜ç»“æ„åŒ– JSON
    output_data = {
        "script_id": script_id,
        "full_text": full_text,
        "segments": segments
    }
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… ç»“æ„åŒ–æ•°æ®å·²ä¿å­˜: {json_path}")

    # 4. ä¿å­˜ SRT å­—å¹•
    with open(srt_path, "w", encoding="utf-8") as f:
        for seg in segments:
            start_str = format_time(seg['start'])
            end_str = format_time(seg['end'])
            f.write(f"{seg['id']}\n{start_str} --> {end_str}\n{seg['text']}\n\n")
    
    print(f"âœ… å­—å¹•å·²ä¿å­˜: {srt_path}")
    return True

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python transcribe_funasr.py <script_id>")
        sys.exit(1)
    transcribe(sys.argv[1])