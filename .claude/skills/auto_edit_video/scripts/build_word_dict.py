#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ„å»ºä¿®æ­£åçš„è¯è¯­æ—¶é—´çº¿å­—å…¸
ä½¿ç”¨æŒ‰ä½ç½®å¯¹é½ç®—æ³•ï¼šä¿æŒ Whisper çš„åˆ†è¯å’Œæ—¶é—´è½´ï¼Œåªä¿®æ­£æ–‡æœ¬å†…å®¹
"""
import json
import os
import sys
import io
from pathlib import Path
from utils import get_script_paths

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if hasattr(sys.stdout, 'buffer'):
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
if hasattr(sys.stderr, 'buffer'):
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

def clean_text(text):
    """ç§»é™¤æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼ï¼Œç”¨äºæ–‡æœ¬å¯¹é½"""
    import string
    punctuation = 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€,."\'!?;:""\'\'ï¼ˆï¼‰()ã€ã€‘[]ã€Šã€‹<>Â·â€”â€¦ï½ï½œ/\\-_=+*&^%$#@`~ \n'
    punctuation += string.punctuation
    return ''.join(c for c in text if c not in punctuation)

def align_by_position(whisper_words, refined_text):
    """
    æŒ‰é¡ºåºä½ç½®å¯¹é½ç®—æ³•ï¼ˆåŸºäºæ¯”ä¾‹åˆ†é…ï¼‰
    
    ç­–ç•¥ï¼š
    1. è®¡ç®— Whisper æ€»å­—ç¬¦æ•°å’Œ Refined æ€»å­—ç¬¦æ•°
    2. è®¡ç®—åˆ†å¸ƒæ¯”ä¾‹ ratio
    3. æŒ‰ ratio å°† refined_text å‡åŒ€åˆ†é…ç»™æ¯ä¸ª whisper å•è¯
    
    ä¼˜åŠ¿ï¼š
    - ç¡®ä¿ refined_text çš„æ‰€æœ‰å­—ç¬¦éƒ½è¢«åŒ…å«åœ¨æ—¶é—´çº¿å†…
    - è§£å†³ refined.txt å˜é•¿å¯¼è‡´æ–‡æ¡ˆè¢«æˆªæ–­çš„é—®é¢˜
    
    Args:
        whisper_words: Whisper åˆ†è¯åˆ—è¡¨ï¼ˆå¸¦æ ‡ç‚¹ï¼‰
        refined_text: ä¼˜åŒ–åçš„æ–‡æœ¬ï¼ˆå»é™¤æ¢è¡Œï¼‰
    
    Returns:
        å¯¹é½åçš„è¯è¯­åˆ—è¡¨
    """
    refined_clean = clean_text(refined_text)
    
    # è®¡ç®— Whisper æ¸…æ´—åçš„æ€»é•¿åº¦
    whisper_clean_lens = [len(clean_text(w)) for w in whisper_words]
    total_whisper_len = sum(whisper_clean_lens)
    total_refined_len = len(refined_clean)
    
    print(f"ğŸ“Š å¯¹é½ç»Ÿè®¡:")
    print(f"  - Whisper è¯æ•°: {len(whisper_words)}")
    print(f"  - Whisper å­—ç¬¦æ•°: {total_whisper_len}")
    print(f"  - Refined å­—ç¬¦æ•°: {total_refined_len}")
    
    if total_whisper_len == 0:
        ratio = 1.0
    else:
        ratio = total_refined_len / total_whisper_len
        
    print(f"  - å­—ç¬¦è†¨èƒ€æ¯”: {ratio:.3f}")
    
    aligned_words = []
    current_refined_pos = 0
    accumulated_target = 0.0
    
    for i, w_word in enumerate(whisper_words):
        w_len = whisper_clean_lens[i]
        
        # å¦‚æœæ˜¯çº¯æ ‡ç‚¹ï¼Œä¿ç•™åŸæ ‡ç‚¹ï¼ˆè™½ç„¶ä¼šè¢«æ¸…æ´—æ‰ï¼Œä½†ä¿æŒç»“æ„å®Œæ•´ï¼‰
        if w_len == 0:
            aligned_words.append(w_word)
            continue
            
        # è®¡ç®—å½“å‰è¯åº”è¯¥åˆ†åˆ°çš„å­—ç¬¦æ•°
        accumulated_target += w_len * ratio
        target_end_pos = int(round(accumulated_target))
        
        # ç¡®ä¿ä¸è¶Šç•Œ
        target_end_pos = min(target_end_pos, total_refined_len)
        
        # æå–å¯¹åº”çš„ refined æ–‡æœ¬
        chunk_len = target_end_pos - current_refined_pos
        
        if chunk_len > 0:
            chunk = refined_clean[current_refined_pos : target_end_pos]
            aligned_words.append(chunk)
            current_refined_pos = target_end_pos
        else:
            # å¦‚æœæ¯”ä¾‹å¾ˆå°å¯¼è‡´ä¸éœ€è¦åˆ†é…å­—ç¬¦ï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²æˆ–è€…åŸè¯ï¼Ÿ
            # è¿™é‡Œçš„ç­–ç•¥æ˜¯ï¼šå¦‚æœæ²¡æœ‰åˆ†é…åˆ°å­—ç¬¦ï¼Œå°±ç»™ä¸ªç©ºå­—ç¬¦ä¸²ï¼Œè¿™æ ·ä¸ä¼šå ç”¨æ—¶é—´
            # ä½†ä¸ºäº†é˜²æ­¢ç©ºæ´ï¼Œå¦‚æœè¿˜å‰©å­—ç¬¦ï¼Œè‡³å°‘ç»™ä¸€ä¸ªï¼Ÿ
            # å®é™…ä¸Š round() æœºåˆ¶åº”è¯¥èƒ½å¤„ç†å¥½
            aligned_words.append("")
            
    # å…œåº•ï¼šå¦‚æœè¿˜æœ‰å‰©ä½™å­—ç¬¦ï¼Œå…¨éƒ¨è¿½åŠ åˆ°æœ€åä¸€ä¸ªéç©ºè¯
    if current_refined_pos < total_refined_len:
        remaining = refined_clean[current_refined_pos:]
        print(f"âš ï¸ è¿˜æœ‰ {len(remaining)} ä¸ªæœªåˆ†é…å­—ç¬¦ï¼Œè¿½åŠ åˆ°æœ«å°¾")
        if aligned_words:
            # æ‰¾åˆ°æœ€åä¸€ä¸ªéçº¯æ ‡ç‚¹çš„ slot
            for j in range(len(aligned_words)-1, -1, -1):
                if aligned_words[j] and clean_text(aligned_words[j]):
                    aligned_words[j] += remaining
                    break
    
    # ç®€å•çš„éªŒè¯
    total_aligned_len = sum(len(clean_text(w)) for w in aligned_words)
    print(f"ğŸ“ æœ€ç»ˆåˆ†é…å­—ç¬¦æ•°: {total_aligned_len} (åº”ä¸º {total_refined_len})")
    
    return aligned_words

def build_word_dict(script_id):
    """
    æ„å»ºä¿®æ­£åçš„è¯è¯­æ—¶é—´çº¿å­—å…¸
    
    è¾“å…¥:
        - refined.txt: DeepSeek ä¼˜åŒ–åçš„æ–‡æœ¬
        - whisper.json: Whisper è¯è¯­çº§åˆ«æ—¶é—´è½´
    
    è¾“å‡º:
        - refined_word_dict.json: ä¿®æ­£åçš„è¯è¯­æ—¶é—´çº¿å­—å…¸
    """
    paths = get_script_paths(script_id)
    
    refined_txt_path = paths["copy_refined"]
    whisper_json_path = paths["caption_whisper_json"]
    output_path = paths["caption_refined_json"]
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not refined_txt_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ° refined.txt: {refined_txt_path}")
        return False
    
    if not whisper_json_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ° whisper.json: {whisper_json_path}")
        return False
    
    print(f"ğŸ”¨ æ­£åœ¨æ„å»ºè¯è¯­æ—¶é—´çº¿å­—å…¸ï¼ˆæŒ‰ä½ç½®å¯¹é½ç®—æ³•ï¼‰...")
    print(f"ğŸ“„ è¯»å–ä¼˜åŒ–æ–‡æœ¬: {refined_txt_path}")
    
    # 1. è¯»å– refined.txt
    with open(refined_txt_path, 'r', encoding='utf-8') as f:
        refined_text = f.read()
    
    # 2. è¯»å– whisper.json
    with open(whisper_json_path, 'r', encoding='utf-8') as f:
        whisper_data = json.load(f)
        whisper_segments = whisper_data['segments']
    
    print(f"ğŸ“Š åŸå§‹è¯è¯­æ•°: {len(whisper_segments)}")
    
    # 3. æå– Whisper çš„è¯è¯­åˆ—è¡¨
    whisper_words = [seg['text'] for seg in whisper_segments]
    
    # 4. æŒ‰é¡ºåºä½ç½®å¯¹é½ï¼ˆä¸è¿›è¡Œæ–‡æœ¬åŒ¹é…ï¼‰
    refined_text_clean = refined_text.replace('\n', '')
    aligned_words = align_by_position(whisper_words, refined_text_clean)
    
    # 5. æ„å»ºæ–°çš„ segmentsï¼ˆä¿æŒæ—¶é—´è½´ï¼Œæ›´æ–°æ–‡æœ¬ï¼‰
    refined_segments = []
    for i, seg in enumerate(whisper_segments):
        if i < len(aligned_words):
            refined_segments.append({
                "id": seg['id'],
                "start": seg['start'],
                "end": seg['end'],
                "text": aligned_words[i]
            })
        else:
            # å¦‚æœå¯¹é½å¤±è´¥ï¼Œä¿ç•™åŸæ–‡
            refined_segments.append(seg)
    
    # 6. ç”Ÿæˆä¿®æ­£åçš„è¯è¯­æ—¶é—´çº¿å­—å…¸
    refined_word_dict = {
        "script_id": script_id,
        "full_text": refined_text,
        "segments": refined_segments,
        "segment_mode": "word_level_refined",
        "total_words": len(refined_segments),
        "note": "ä¿®æ­£åçš„è¯è¯­æ—¶é—´çº¿å­—å…¸ï¼ˆæŒ‰ä½ç½®å¯¹é½ï¼šä¿æŒåˆ†è¯+æ—¶é—´è½´ï¼ŒæŒ‰é¡ºåºæ›¿æ¢æ–‡æœ¬ï¼‰"
    }
    
    # 7. ä¿å­˜
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(refined_word_dict, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… è¯è¯­æ—¶é—´çº¿å­—å…¸æ„å»ºå®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"ğŸ“Š ä¿®æ­£è¯è¯­æ•°: {len(refined_segments)}")
    print(f"\né¢„è§ˆå‰10ä¸ªè¯:")
    for seg in refined_segments[:10]:
        print(f"  [{seg['start']:.3f}-{seg['end']:.3f}] \"{seg['text']}\"")
    
    return True

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python build_word_dict.py <script_id>")
        print("è¯´æ˜: å°† refined.txt æ˜ å°„åˆ° whisper.json çš„è¯è¯­æ—¶é—´è½´")
        sys.exit(1)
    
    build_word_dict(sys.argv[1])
