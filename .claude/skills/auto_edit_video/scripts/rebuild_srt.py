#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºè¯è¯­æ—¶é—´çº¿å­—å…¸é‡å»º SRT å­—å¹•ï¼ˆæ–°ç‰ˆæœ¬ï¼‰
è¾“å…¥:
  - refined.txt: DeepSeek ä¼˜åŒ–åçš„æ–­å¥æ–‡æœ¬
  - refined_word_dict.json: ä¿®æ­£åçš„è¯è¯­æ—¶é—´çº¿å­—å…¸
è¾“å‡º:
  - final.srt: æœ€ç»ˆå­—å¹•æ–‡ä»¶
"""
import json
import os
import sys
import io
from pathlib import Path
from utils import get_script_paths

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if hasattr(sys.stdout, 'buffer'):
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
if hasattr(sys.stderr, 'buffer'):
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

def format_time(seconds):
    """å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼"""
    millis = int((seconds - int(seconds)) * 1000)
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

def clean_text_for_match(text):
    """
    æ¸…ç†æ–‡æœ¬ç”¨äºåŒ¹é…ï¼šç§»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼
    åªä¿ç•™æ±‰å­—ã€å­—æ¯ã€æ•°å­—
    """
    import string
    # ä¸­æ–‡æ ‡ç‚¹ + è‹±æ–‡æ ‡ç‚¹ + å…¶ä»–ç¬¦å·
    punctuation = 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€,."\'!?;:""''ï¼ˆï¼‰()ã€ã€‘[]ã€Šã€‹<>Â·â€”â€¦ï½ï½œ/\\-_=+*&^%$#@`~'
    punctuation += string.punctuation  # æ·»åŠ æ‰€æœ‰è‹±æ–‡æ ‡ç‚¹
    
    # ç§»é™¤æ‰€æœ‰æ ‡ç‚¹å’Œç©ºæ ¼
    cleaned = ''.join(c for c in text if c not in punctuation and c.strip())
    return cleaned

def find_text_by_position(text, word_dict_segments, cumulative_char_pos, segment_char_positions):
    """
    æŒ‰ç´¯è®¡å­—ç¬¦ä½ç½®åˆ‡åˆ†æ—¶é—´çº¿ï¼ˆæ”¹è¿›ç®—æ³•ï¼‰
    
    ç­–ç•¥ï¼š
    1. é¢„å…ˆè®¡ç®—æ¯ä¸ª segment çš„ç´¯è®¡å­—ç¬¦ä½ç½®
    2. æ ¹æ®å½“å‰è¡Œçš„ç´¯è®¡èµ·æ­¢ä½ç½®ï¼Œæ‰¾åˆ°è¦†ç›–è¿™ä¸ªèŒƒå›´çš„ segments
    3. è¿”å›è¿™äº› segments çš„èµ·æ­¢æ—¶é—´
    
    è¿™æ ·å¯ä»¥é¿å…å­—ç¬¦æµªè´¹ï¼Œç¡®ä¿æ‰€æœ‰è¡Œéƒ½èƒ½è·å¾—æ—¶é—´çº¿
    
    Args:
        text: å­—å¹•æ–‡æœ¬
        word_dict_segments: è¯è¯­æ—¶é—´çº¿åˆ—è¡¨
        cumulative_char_pos: å½“å‰è¡Œçš„èµ·å§‹ç´¯è®¡å­—ç¬¦ä½ç½®
        segment_char_positions: é¢„è®¡ç®—çš„æ¯ä¸ª segment çš„ (start_pos, end_pos)
    
    Returns:
        (start_time, end_time, next_cumulative_pos)
    """
    # è®¡ç®—ç›®æ ‡å­—ç¬¦æ•°ï¼ˆå»é™¤æ ‡ç‚¹ï¼‰
    text_clean = clean_text_for_match(text)
    target_char_count = len(text_clean)
    
    if target_char_count == 0:
        return None, None, cumulative_char_pos
    
    # è®¡ç®—å½“å‰è¡Œçš„å­—ç¬¦èŒƒå›´
    line_start = cumulative_char_pos
    line_end = cumulative_char_pos + target_char_count
    
    # æ‰¾åˆ°è¦†ç›–è¿™ä¸ªèŒƒå›´çš„ segments
    matched_segments = []
    for i, (seg_start, seg_end) in enumerate(segment_char_positions):
        # å¦‚æœ segment å’Œå½“å‰è¡Œæœ‰äº¤é›†
        if seg_end > line_start and seg_start < line_end:
            matched_segments.append(word_dict_segments[i])
    
    if matched_segments:
        start_time = matched_segments[0]['start']
        end_time = matched_segments[-1]['end']
        return start_time, end_time, line_end
    else:
        return None, None, cumulative_char_pos

def rebuild_srt_v2(script_id):
    """
    åŸºäºè¯è¯­æ—¶é—´çº¿å­—å…¸é‡å»º SRT
    """
    paths = get_script_paths(script_id)
    
    refined_txt_path = paths["copy_refined"]
    word_dict_path = paths["caption_refined_json"]
    output_srt_path = paths["caption_final_srt"]
    
    if not refined_txt_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ° refined.txt: {refined_txt_path}")
        return False
    
    if not word_dict_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è¯è¯­å­—å…¸: {word_dict_path}")
        return False
    
    print(f"ğŸ”¨ æ­£åœ¨é‡å»º SRT å­—å¹•...")
    
    # 1. è¯»å– refined.txtï¼ˆæŒ‰è¡Œåˆ†æ®µçš„å­—å¹•æ–‡æœ¬ï¼‰
    with open(refined_txt_path, 'r', encoding='utf-8') as f:
        refined_lines = [line.strip() for line in f if line.strip()]
    
    # 2. è¯»å–è¯è¯­æ—¶é—´çº¿å­—å…¸
    with open(word_dict_path, 'r', encoding='utf-8') as f:
        word_dict = json.load(f)
        word_segments = word_dict['segments']
    
    # âš ï¸ æ•°æ®æ ¼å¼éªŒè¯ï¼šç¡®ä¿æ˜¯è¯çº§å­—å…¸
    segment_mode = word_dict.get('segment_mode', 'unknown')
    if segment_mode != 'word_level_refined':
        print(f"âš ï¸ è­¦å‘Šï¼šè¯å…¸æ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼")
        print(f"   æœŸæœ›: 'word_level_refined'")
        print(f"   å®é™…: '{segment_mode}'")
        print(f"   è¿™å¯èƒ½å¯¼è‡´æ—¶é—´çº¿é”™è¯¯ã€‚è¯·å…ˆè¿è¡Œ build_word_dict.py")
    
    print(f"ğŸ“ å­—å¹•è¡Œæ•°: {len(refined_lines)}")
    print(f"ğŸ“Š è¯å…¸è¯æ•°: {len(word_segments)}")
    print(f"ğŸ“‹ è¯å…¸æ¨¡å¼: {segment_mode}")
    
    # 3. é¢„è®¡ç®—æ¯ä¸ª segment çš„ç´¯è®¡å­—ç¬¦ä½ç½®
    segment_char_positions = []
    cumulative_pos = 0
    for seg in word_segments:
        seg_clean = clean_text_for_match(seg['text'])
        seg_len = len(seg_clean)
        segment_char_positions.append((cumulative_pos, cumulative_pos + seg_len))
        cumulative_pos += seg_len
    
    print(f"ğŸ“Š æ€»å­—ç¬¦æ•°: {cumulative_pos}")
    
    # 4. ä¸ºæ¯è¡Œå­—å¹•æŒ‰ç´¯è®¡å­—ç¬¦ä½ç½®åˆ‡åˆ†æ—¶é—´çº¿ï¼ˆæ”¹è¿›ç®—æ³•ï¼šé¿å…å­—ç¬¦æµªè´¹ï¼‰
    subtitle_entries = []
    current_char_pos = 0  # è·Ÿè¸ªå½“å‰ç´¯è®¡å­—ç¬¦ä½ç½®
    
    for i, line in enumerate(refined_lines):
        start_time, end_time, next_pos = find_text_by_position(
            line, word_segments, current_char_pos, segment_char_positions
        )
        
        if start_time is not None and end_time is not None:
            subtitle_entries.append({
                "id": i + 1,
                "start": start_time,
                "end": end_time,
                "text": line
            })
            current_char_pos = next_pos  # æ›´æ–°ç´¯è®¡å­—ç¬¦ä½ç½®
            print(f"  âœ… ç¬¬{i+1}è¡Œ: [{start_time:.2f}-{end_time:.2f}] {line[:30]}...")
        else:
            print(f"  âš ï¸ ç¬¬{i+1}è¡Œ: æœªæ‰¾åˆ°åŒ¹é… - {line[:30]}...")
    
    # ğŸ”§ ä¿®å¤æ—¶é—´çº¿é—®é¢˜ï¼šç¡®ä¿æ—¶é—´çº¿ä¸é‡å ã€ä¸é—´éš™
    print(f"\nğŸ”§ ä¿®å¤æ—¶é—´çº¿é—®é¢˜...")
    
    # æ­¥éª¤1ï¼šä»åå¾€å‰ä¿®å¤é‡å ï¼ˆæ™ºèƒ½åˆ†å‰²é‡å æ—¶é—´æ®µï¼‰
    overlaps_fixed = 0
    for i in range(len(subtitle_entries) - 1, 0, -1):  # ä»æœ€åä¸€æ¡å¾€å‰éå†
        current = subtitle_entries[i]
        prev_entry = subtitle_entries[i - 1]
        
        # å¦‚æœæœ‰é‡å ï¼ˆå‰ä¸€è¡Œçš„ç»“æŸæ—¶é—´ > åä¸€è¡Œçš„å¼€å§‹æ—¶é—´ï¼‰
        if prev_entry['end'] > current['start']:
            # ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœå¼€å§‹æ—¶é—´ç›¸åŒï¼ŒæŒ‰æ¯”ä¾‹åˆ†å‰²
            if prev_entry['start'] == current['start']:
                # è®¡ç®—æ€»æ—¶é•¿å’Œå„è‡ªçš„å­—ç¬¦æ•°
                total_duration = max(prev_entry['end'], current['end']) - prev_entry['start']
                prev_chars = len(clean_text_for_match(prev_entry['text']))
                curr_chars = len(clean_text_for_match(current['text']))
                total_chars = prev_chars + curr_chars
                
                if total_chars > 0:
                    # æŒ‰å­—ç¬¦æ•°æ¯”ä¾‹åˆ†å‰²æ—¶é—´
                    prev_ratio = prev_chars / total_chars
                    split_point = prev_entry['start'] + total_duration * prev_ratio
                    prev_entry['end'] = split_point
                    current['start'] = split_point
            else:
                # æ™®é€šé‡å ï¼šå‰ä¸€è¡Œç»“æŸæ—¶é—´ = åä¸€è¡Œå¼€å§‹æ—¶é—´
                prev_entry['end'] = current['start']
            overlaps_fixed += 1
    
    # æ­¥éª¤2ï¼šä»å‰å¾€åä¿®å¤é—´éš™ï¼ˆå‰ä¸€è¡Œç»“æŸæ—¶é—´ = åä¸€è¡Œå¼€å§‹æ—¶é—´ï¼‰
    gaps_fixed = 0
    for i in range(len(subtitle_entries) - 1):
        current = subtitle_entries[i]
        next_entry = subtitle_entries[i + 1]
        
        # å¦‚æœæœ‰é—´éš™ï¼Œå°†å½“å‰æ¡çš„ç»“æŸæ—¶é—´è®¾ä¸ºä¸‹ä¸€æ¡çš„å¼€å§‹æ—¶é—´
        if next_entry['start'] > current['end']:
            gap = next_entry['start'] - current['end']
            if gap > 0.001:  # é—´éš™å¤§äº1æ¯«ç§’
                current['end'] = next_entry['start']
                gaps_fixed += 1
    
    if overlaps_fixed > 0:
        print(f"  âœ… ä¿®å¤äº† {overlaps_fixed} ä¸ªæ—¶é—´çº¿é‡å ")
    if gaps_fixed > 0:
        print(f"  âœ… ä¿®å¤äº† {gaps_fixed} ä¸ªæ—¶é—´çº¿é—´éš™")
    if overlaps_fixed == 0 and gaps_fixed == 0:
        print(f"  âœ… æ—¶é—´çº¿å·²è¿ç»­ï¼Œæ— éœ€ä¿®å¤")
    
    # 4. ç”Ÿæˆ SRT
    srt_content = []
    for entry in subtitle_entries:
        # å»é™¤æœ«å°¾æ ‡ç‚¹ç¬¦å·
        text = entry['text'].rstrip('ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€,."\'!?;:')
        
        srt_content.append(f"{entry['id']}")
        srt_content.append(f"{format_time(entry['start'])} --> {format_time(entry['end'])}")
        srt_content.append(text)
        srt_content.append("")
    
    # 5. ä¿å­˜
    with open(output_srt_path, 'w', encoding='utf-8') as f:
        f.write("\n".join(srt_content))
    
    print(f"\nâœ… SRT é‡å»ºå®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_srt_path}")
    print(f"ğŸ“Š å­—å¹•æ¡æ•°: {len(subtitle_entries)}")
    
    return True

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python rebuild_srt_v2.py <script_id>")
        print("è¯´æ˜: åŸºäºè¯è¯­æ—¶é—´çº¿å­—å…¸é‡å»º SRT å­—å¹•")
        sys.exit(1)
    
    rebuild_srt_v2(sys.argv[1])
